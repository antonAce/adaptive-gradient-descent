{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIttKz-mrKtQ"
   },
   "source": [
    "# Rosenbrock function optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as colormaps\n",
    "\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(F: Callable, x: np.array, h=0.001):\n",
    "    n = len(x)\n",
    "    grad = np.zeros(x.shape)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Step with h size in a single direction for single variable\n",
    "        # other values keep same\n",
    "        vh = h * np.eye(1, n, i).reshape((n, ))\n",
    "        \n",
    "        # Applying finite differences for each variable\n",
    "        grad[i] = (F(x + vh) - F(x - vh)) / (2.0 * h)\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3d surface print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JoWaBwchRem"
   },
   "outputs": [],
   "source": [
    "def plot_grid(F: Callable[[np.array, np.array], np.array],\n",
    "              X: np.array, Y: np.array,\n",
    "              elev=30, azim=50, ax=None):\n",
    "    \"\"\"\n",
    "    Plots 3D surface grid for 2 independent\n",
    "    parameters and estimation equation\n",
    "    :param F: estimation equation\n",
    "    :param X: first independent parameter\n",
    "    :param Y: second independent parameter\n",
    "    :param elev: vertical rotation angle\n",
    "    :param azim: horizontal rotation angle\n",
    "    :param ax: predefined plotting axis\n",
    "    :return: generated plotting axis\n",
    "    \"\"\"\n",
    "\n",
    "    # Generating grid\n",
    "    x, y = np.meshgrid(X, Y)\n",
    "\n",
    "    # If grid plotting axis is not defined above,\n",
    "    # the new one will be created.\n",
    "    if ax is None:\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "    # Plotting grid\n",
    "    surf = ax.plot_surface(x, y, F(x, y), \n",
    "                         cmap=colormaps.coolwarm, \n",
    "                         antialiased=True)\n",
    "    fig.colorbar(surf)\n",
    "\n",
    "    # For axis reusability purposes\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hxi4Z5tF7C0c"
   },
   "source": [
    "The following code demonstrates the optimization problem for the **Rosenbrock function**:\n",
    "\n",
    "$F(x, y) = (1 - x)^{2} + 100(y - x^{2})^{2}$\n",
    "\n",
    "Function has a single local minimum in $(x, y) = (1, 1)$ and is equal $F(x, y) = 0$ in the following point.\n",
    "\n",
    "The gradient value, by definition, is a vector that points towards the direction of the greatest increase of the function. In order to reach a local minimum using an iterative algorithm, the next step should be in the direction opposite to the gradient value. So the full algorithm of finding local minimum can be described as $x_{i+1} = x_{i} - \\lambda_{i}\\nabla F$, where $\\lambda_{i} = const$ - size of a single step, $x_{i}$ - current step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vUIAbHGDosX",
    "outputId": "16e83c3e-6ac1-41ef-9fe0-749c14883ea3"
   },
   "outputs": [],
   "source": [
    "# Single iteration of an algorithm\n",
    "def gradient_step(alpha: tf.constant, x: tf.Variable, y: tf.Variable) -> tf.Variable:\n",
    "    with tf.GradientTape() as grad:\n",
    "        grad.watch((alpha, x, y))\n",
    "\n",
    "        # Optimization function\n",
    "        F = (1.0 - x) ** 2.0 + 100.0 * (y - x ** 2.0) ** 2.0\n",
    "        [dF_dx, dF_dy] = grad.gradient(F, [x, y])\n",
    "\n",
    "    return x - alpha * tf.Variable(dF_dx), y - alpha * tf.Variable(dF_dy)\n",
    "\n",
    "# Gradient steps\n",
    "steps = 1000\n",
    "\n",
    "# Gradient step size\n",
    "alpha = tf.constant(0.001)\n",
    "\n",
    "# Start conditions\n",
    "x = tf.Variable(2.0)\n",
    "y = tf.Variable(-1.0)\n",
    "\n",
    "# Iterations\n",
    "xi_yi = np.array([x.numpy(), y.numpy()])\n",
    "\n",
    "for _ in range(steps):\n",
    "    # Iterative descent\n",
    "    x, y = gradient_step(alpha, x, y)\n",
    "    xi_yi = np.vstack((xi_yi, np.array([x.numpy(), y.numpy()])))\n",
    "\n",
    "print(f\"Closest approximation of the local minimum: [{xi_yi[steps, 0]}, {xi_yi[steps, 1]}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zot5L5JYPsoZ"
   },
   "source": [
    "Visualisation intervals and rendering density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRN-l53dQYOY"
   },
   "outputs": [],
   "source": [
    "density = 0.1\n",
    "\n",
    "X = np.arange(-2.0, 2.0, density)\n",
    "Y = np.arange(-1.0, 3.0, density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56X8X1STQ9me"
   },
   "source": [
    "**Rosenbrock function** in vector form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHBj069xRA7C"
   },
   "outputs": [],
   "source": [
    "F = lambda x, y: (1.0 - x) ** 2.0 + 100.0 * (y - x ** 2.0) ** 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4VjiX-7Tpvk"
   },
   "source": [
    "Descent visualisation for space $(x, y) \\in \\{ -2 \\leq x \\leq 2; -1 \\leq y \\leq 3 \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "nSVseTsxJN1K",
    "outputId": "a7b495c8-f9b5-473c-eda6-e0c5015922cb"
   },
   "outputs": [],
   "source": [
    "ax = plot_grid(F, X, Y)\n",
    "ax.plot(xi_yi[:, 0].T, xi_yi[:, 1].T, F(xi_yi[:, 0], xi_yi[:, 1]).T,\n",
    "        lw=0.5, marker='*', color='black')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rosenbrock_optimization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
