{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "gradient_descent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIttKz-mrKtQ"
      },
      "source": [
        "# Adaptive Stochastic Gradient Descent\n",
        "\n",
        "Implementation and comparison of adaptive stochastic gradient descent methods using Python programming language. The efficiency comparison is demonstrated in the logistic regression optimization problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2BS-jAgrKtU"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "**Gradient descent** is one of the most popular numerical methods for solving modern optimization problems: from cost reduction to neural networks training. The thing that all these problems have in common is an aim to describe it as a mathematical model (e.g. mathematical equation) $J(\\theta_{i})$, which has a set of independent parameters $\\theta_{i}$, and then find specific values of $\\theta_{i}$ so $J(\\theta_{i})$ will reach the minimum possible value. As an example, in neural network training $J(\\theta_{i})$ can be described as a loss between the expected training example and the actual one, where $\\theta_{i}$ will be the **weight coefficients** of the neural network. So the goal of the training process is to find the optimal value of **weight coefficients**, so the loss will become minimum and the output value of a neural network will become as close to expected as possible.\n",
        "\n",
        "By definition, the **gradient** is a vector that points towards the highest  increase of the function value $F$ in high dimensional space $R^{n}$, that can be interpreted as a vector of partial derivatives with respect to each parameter $x_{1}, ..., x_{n}$ of the function $F$ in the specific point $a$:\n",
        "\n",
        "$\\nabla F(a) = \\begin{bmatrix}\n",
        "\\frac{\\partial f}{\\partial x_{1}} (a) \\\\\n",
        "\\vdots \\\\\n",
        "\\frac{\\partial f}{\\partial x_{n}} (a) \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Various optimization algorithms, which are based on **gradient descent**, have common feature: usage of a vector, opposite to the gradient value (antigradient or $- \\nabla F$), as the key direction to the function minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WUIVxN9nnRR"
      },
      "source": [
        "### Overviewed algorithms\n",
        "\n",
        "- SGD\n",
        "- Dynamic Sampling SGD\n",
        "- Mini-batch SGD\n",
        "- Nesterov AG\n",
        "- ADAGRAD\n",
        "- RMSPROP\n",
        "- ADAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slca3rLNdWMr"
      },
      "source": [
        "### Tensorflow API usage\n",
        "\n",
        "**Gradient values** calculation will be speeded up for overviewed methods using [computation graphs](https://www.tensorflow.org/api_docs/python/tf/Graph) from [TensorFlow framework API](https://github.com/tensorflow/tensorflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JoWaBwchRem"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2LhrVMwhfsZ"
      },
      "source": [
        "Tensorflow framework provides class [tf.GradientTape()](https://www.tensorflow.org/api_docs/python/tf/GradientTape) with a set of methods for required computations: [gradient()](https://www.tensorflow.org/api_docs/python/tf/GradientTape#gradient) and [jacobian()](https://www.tensorflow.org/api_docs/python/tf/GradientTape#jacobian). The following section contains examples of gradient computations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COfQP4_KjA_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d59218-df76-4d3b-a983-c7512a91a7a0"
      },
      "source": [
        "# Defining the scope of gradient computation. Here all defined variables\n",
        "# will be registered in Tensorflow calculation graph.\n",
        "with tf.GradientTape(persistent=True) as grad:\n",
        "  x, y = (tf.Variable(2.0), tf.Variable(-1.0))\n",
        "\n",
        "  # Single variable equation\n",
        "  f = x ** 3 + 2 * x ** 2 + 12 * x + 100\n",
        "\n",
        "  # Multiple variable equation\n",
        "  F = x ** 2 + x * y + y ** 2\n",
        "\n",
        "# f'(x) = 3 * x ** 2 + 4 * x + 12, f'(2.0) = 32.0\n",
        "df = grad.gradient(f, x)\n",
        "\n",
        "# dFdx = 2 * x + y, dFdx(2.0, -1.0) = 3.0\n",
        "# dFdy = x + 2 * y, dFdy(2.0, -1.0) = 0.0\n",
        "[dFdx, dFdy] = grad.gradient(F, [x, y])\n",
        "\n",
        "# Release graph allocated memory\n",
        "del grad\n",
        "\n",
        "print(f'Single variable equation:\\nf\\'(2.0) = {df};\\n')\n",
        "print(f'Multiple variable equation:\\ndFdx(2.0, -1.0) = {dFdx};\\ndFdy(2.0, -1.0) = {dFdy};')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single variable equation:\n",
            "f'(2.0) = 32.0;\n",
            "\n",
            "Multiple variable equation:\n",
            "dFdx(2.0, -1.0) = 3.0;\n",
            "dFdy(2.0, -1.0) = 0.0;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co80AuAYRkr1"
      },
      "source": [
        "### Tensor operations\n",
        "\n",
        "All tensor-like structure wrappers and operation methods for them are used from [Numpy](https://github.com/numpy/numpy) package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOJFSXKHRs_g"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmpSqbXtTZvY"
      },
      "source": [
        "### Algorithm convergence visualisation\n",
        "\n",
        "Iterations of the each **gradient descent** algorithm can be plotted as the path on 3D surface, in case model has only 2 independent parameters $\\{ \\theta_{1}, \\theta_{2} \\}$ so they can represent $X$ and $Y$ axises, and remaining $Z$ axis represents value of estimation equation to optimize $J(\\theta_{1}, \\theta_{2})$. All visualisation tools are used from [matplotlib](https://github.com/matplotlib/matplotlib) package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow88b6ykaCXq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as colormaps"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1uHa2ImsASP"
      },
      "source": [
        "Useful plotting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTxudbAruJ8w"
      },
      "source": [
        "from typing import Callable\n",
        "\n",
        "\n",
        "def plot_grid(F: Callable[[np.array, np.array], np.array],\n",
        "              X: np.array, Y: np.array,\n",
        "              elev=30, azim=50, ax=None):\n",
        "  \"\"\"\n",
        "  Plots 3D surface grid for 2 independent\n",
        "  parameters and estimation equation\n",
        "  :param F: estimation equation\n",
        "  :param X: first independent parameter\n",
        "  :param Y: second independent parameter\n",
        "  :param elev: vertical rotation angle\n",
        "  :param azim: horizontal rotation angle\n",
        "  :param ax: predefined plotting axis\n",
        "  :return: generated plotting axis\n",
        "  \"\"\"\n",
        "\n",
        "  # Generating grid\n",
        "  x, y = np.meshgrid(X, Y)\n",
        "\n",
        "  # If grid plotting axis is not defined above,\n",
        "  # the new one will be created.\n",
        "  if ax is None:\n",
        "    fig = plt.figure()\n",
        "    ax = fig.gca(projection='3d')\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "\n",
        "  # Plotting grid\n",
        "  surf = ax.plot_surface(x, y, F(x, y), \n",
        "                         cmap=colormaps.coolwarm, \n",
        "                         antialiased=True)\n",
        "  fig.colorbar(surf)\n",
        "\n",
        "  # For axis reusability purposes\n",
        "  return ax"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_bcT9ZEt8qA"
      },
      "source": [
        "### Optimization problem\n",
        "\n",
        "**Logistic regression** is chosen as an example of an optimization problem for comparing the convergence rate of the **gradient descent** algorithms. This mathematical model can be described as a binary classifier, which outputs a probability value of a certain set of features $x_{i}$ to belong to a certain class (e. g. **true** or **false**). Using the definition of optimization problem from above, the classifier can be represented in the form of two components: **an adder** that combines all the characteristics into a single one: $z_{j} = \\sum_{i=1}^{n} \\theta_{i} x_{i, j}$ (or $z_{j} = \\theta^{T} \\cdot x$), and **a converter** that calculates the probability of the characteristics belonging to a certain class based on the output value of **an adder**: $g(a) = \\frac{1}{1 + e^{-a}}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMa-FhBaGySL"
      },
      "source": [
        "# Adder component\n",
        "Z = lambda theta, x: tf.transpose(theta) @ x\n",
        "\n",
        "# Converter component\n",
        "G = lambda a: tf.reshape(1.0 / (1.0 + tf.exp(-a)), shape=())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMHkGn5x-hFF"
      },
      "source": [
        "Assertion examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5p_8pX9-jEE"
      },
      "source": [
        "# x = (0, 0), theta = (1, 1) => g = 0.5\n",
        "tf.assert_equal(G(Z(tf.constant([[1.0], [1.0]]),\n",
        "                    tf.constant([[0.0], [0.0]]))),\n",
        "                tf.constant(0.5))\n",
        "\n",
        "# x = (1, 0), theta = (1, 1) => g = 0.7310586\n",
        "tf.assert_equal(G(Z(tf.constant([[1.0], [1.0]]),\n",
        "                    tf.constant([[1.0], [0.0]]))),\n",
        "                tf.constant(0.7310586))\n",
        "\n",
        "# x = (0, -1), theta = (1, 1) => g = 0.26894143\n",
        "tf.assert_equal(G(Z(tf.constant([[1.0], [1.0]]),\n",
        "                    tf.constant([[0.0], [-1.0]]))),\n",
        "                tf.constant(0.26894143))\n",
        "\n",
        "# x = (0.5, -1), theta = (2, -1.5) => g = 0.9241418\n",
        "tf.assert_equal(G(Z(tf.constant([[2.0], [-1.5]]),\n",
        "                    tf.constant([[0.5], [-1.0]]))),\n",
        "                tf.constant(0.9241418))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFNqrF8XZtiQ"
      },
      "source": [
        "The solution to the problem is to find optimal $\\theta_{i}$ so for input features $x_{i}$ the **loss** $J(\\theta_{i})$ between output value of classifier $\\hat{y_{j}} = g(z_{\\theta}(x_{i, j}))$ and expected value $y_{j}$ will be minimal.\n",
        "\n",
        "Set of classes, mentioned above, can be represented as $\\{ 0, 1 \\}$, e. g. if model output is $1$ - features belog to class, and if $0$ - features do not belog to class. In this case, the rule of fitting regression model can be interpreted as following: *if expected output is $y=1$, loss should approach $0$ when model output approaches $1$ and grow to infinity when model output approaches $0$. For the case $y=0$ these conditions apply vise versa.*\n",
        "\n",
        "Model fitting rule or **loss function** can expressed as limits:\n",
        "\n",
        "$\\begin{cases}\n",
        "\\lim_{g(z_{\\theta}(x_{i, j})) \\to 1} J_{j}(\\theta_{i}) = 0 & \\& & \\lim_{g(z_{\\theta}(x_{i, j})) \\to 0} J_{j}(\\theta_{i}) = \\infty, & y=1 \\\\\n",
        "\\lim_{g(z_{\\theta}(x_{i, j})) \\to 0} J_{j}(\\theta_{i}) = 0 & \\& & \\lim_{g(z_{\\theta}(x_{i, j})) \\to 1} J_{j}(\\theta_{i}) = \\infty, & y=0\n",
        "\\end{cases}$\n",
        "\n",
        "Limitation conditions fit the $\\log(x)$ function, so the **loss function** can be expressed as the following system:\n",
        "\n",
        "$ J_{j}(g, y) = \\begin{cases}\n",
        "-\\log(g), & y = 1  \\\\\n",
        "-\\log(1 - g), & y = 0\n",
        "\\end{cases}$\n",
        "\n",
        "The statement can be joined into a single formula: $ J_{j}(g, y) = - y \\log(g) - (1 - y) \\log(1 - g) $ - this formula is appliable for single pair of features and output. For multiple pairs loss value can be calculated as the mean of losses for single pairs: $ J(g, y) = \\frac{1}{m} \\sum_{j=1}^{m} J_{j}(g, y) = \\frac{1}{m} \\sum_{j=1}^{m} ( - y \\log(g) - (1 - y) \\log(1 - g) ) = -\\frac{1}{m} \\sum_{j=1}^{m} (y \\log(g) + (1 - y) \\log(1 - g) )$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcOekGMr8o56"
      },
      "source": [
        "# Loss function\n",
        "J = lambda g, y: - y * tf.math.log(g) - (1 - y) * tf.math.log(1 - g)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrcV2vLPFCQP"
      },
      "source": [
        "Assertion examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9GMdbLYFDmS"
      },
      "source": [
        "np.testing.assert_almost_equal(\n",
        "    J(tf.constant(0.0001), tf.constant(0.0)).numpy(),\n",
        "    0.00010002)\n",
        "\n",
        "np.testing.assert_almost_equal(\n",
        "    J(tf.constant(0.9998), tf.constant(1.0)).numpy(),\n",
        "    0.00019999)\n",
        "\n",
        "np.testing.assert_almost_equal(\n",
        "    J(tf.constant(0.8), tf.constant(0.0)).numpy(),\n",
        "    1.609438)\n",
        "\n",
        "np.testing.assert_almost_equal(\n",
        "    J(tf.constant(0.2), tf.constant(1.0)).numpy(),\n",
        "    1.609438)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxi4Z5tF7C0c"
      },
      "source": [
        "## Gradient descent variations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5qvxjPtrKtl"
      },
      "source": [
        "## Attribution\n",
        "\n",
        "Overview is based on research paper \"An overview of gradient descent optimization algorithms\" from [arXiv.org](https://arxiv.org/pdf/1609.04747.pdf) by [Sebastian Ruder](mailto:ruder.sebastian@gmail.com) licensed under CC BY-NC-SA 4.0."
      ]
    }
  ]
}