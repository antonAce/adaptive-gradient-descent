{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "gradient_descent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIttKz-mrKtQ"
      },
      "source": [
        "# Adaptive Stochastic Gradient Descent\n",
        "\n",
        "Implementation and comparison of adaptive stochastic gradient descent methods using Python programming language. The efficiency comparison is demonstrated in the logistic regression optimization problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2BS-jAgrKtU"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "**Gradient descent** is one of the most popular numerical methods for solving modern optimization problems: from cost reduction to neural networks training. The thing that all these problems have in common is an aim to describe it as a mathematical model (e.g. mathematical equation) $J(\\theta_{i})$, which has a set of independent parameters $\\theta_{i}$, and then find specific values of $\\theta_{i}$ so $J(\\theta_{i})$ will reach the minimum possible value. As an example, in neural network training $J(\\theta_{i})$ can be described as a loss between the expected training example and the actual one, where $\\theta_{i}$ will be the **weight coefficients** of the neural network. So the goal of the training process is to find the optimal value of **weight coefficients**, so the loss will become minimum and the output value of a neural network will become as close to expected as possible.\n",
        "\n",
        "By definition, the **gradient** is a vector that points towards the highest  increase of the function value $F$ in high dimensional space $R^{n}$, that can be interpreted as a vector of partial derivatives with respect to each parameter $x_{1}, ..., x_{n}$ of the function $F$ in the specific point $a$:\n",
        "\n",
        "$\\nabla F(a) = \\begin{bmatrix}\n",
        "\\frac{\\partial f}{\\partial x_{1}} (a) \\\\\n",
        "\\vdots \\\\\n",
        "\\frac{\\partial f}{\\partial x_{n}} (a) \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Various optimization algorithms, which are based on **gradient descent**, have common feature: usage of a vector, opposite to the gradient value (antigradient or $- \\nabla F$), as the key direction to the function minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WUIVxN9nnRR"
      },
      "source": [
        "### Overviewed algorithms\n",
        "\n",
        "- SGD\n",
        "- Dynamic Sampling SGD\n",
        "- Mini-batch SGD\n",
        "- Nesterov AG\n",
        "- ADAGRAD\n",
        "- RMSPROP\n",
        "- ADAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slca3rLNdWMr"
      },
      "source": [
        "### Tensorflow API usage\n",
        "\n",
        "**Gradient values** calculation will be speeded up for overviewed methods using [computation graphs](https://www.tensorflow.org/api_docs/python/tf/Graph) from [TensorFlow framework API](https://github.com/tensorflow/tensorflow)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JoWaBwchRem"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2LhrVMwhfsZ"
      },
      "source": [
        "Tensorflow framework provides class [tf.GradientTape()](https://www.tensorflow.org/api_docs/python/tf/GradientTape) with a set of methods for required computations: [gradient()](https://www.tensorflow.org/api_docs/python/tf/GradientTape#gradient) and [jacobian()](https://www.tensorflow.org/api_docs/python/tf/GradientTape#jacobian). The following section contains examples of gradient computations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COfQP4_KjA_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a6a6e1d-5362-412e-cf2d-d3dde0b9e46a"
      },
      "source": [
        "# Defining the scope of gradient computation. Here all defined variables\n",
        "# will be registered in Tensorflow calculation graph.\n",
        "with tf.GradientTape(persistent=True) as grad:\n",
        "  x, y = (tf.Variable(2.0), tf.Variable(-1.0))\n",
        "\n",
        "  # Single variable equation\n",
        "  f = x ** 3 + 2 * x ** 2 + 12 * x + 100\n",
        "\n",
        "  # Multiple variable equation\n",
        "  F = x ** 2 + x * y + y ** 2\n",
        "\n",
        "# f'(x) = 3 * x ** 2 + 4 * x + 12, f'(2.0) = 32.0\n",
        "df = grad.gradient(f, x)\n",
        "\n",
        "# dFdx = 2 * x + y, dFdx(2.0, -1.0) = 3.0\n",
        "# dFdy = x + 2 * y, dFdy(2.0, -1.0) = 0.0\n",
        "[dFdx, dFdy] = grad.gradient(F, [x, y])\n",
        "\n",
        "# Release graph allocated memory\n",
        "del grad\n",
        "\n",
        "print(f'Single variable equation:\\nf\\'(2.0) = {df};\\n')\n",
        "print(f'Multiple variable equation:\\ndFdx(2.0, -1.0) = {dFdx};\\ndFdy(2.0, -1.0) = {dFdy};')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Single variable equation:\n",
            "f'(2.0) = 32.0;\n",
            "\n",
            "Multiple variable equation:\n",
            "dFdx(2.0, -1.0) = 3.0;\n",
            "dFdy(2.0, -1.0) = 0.0;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co80AuAYRkr1"
      },
      "source": [
        "### Tensor operations\n",
        "\n",
        "All tensor-like structure wrappers and operation methods for them are used from [Numpy](https://github.com/numpy/numpy) package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOJFSXKHRs_g"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmpSqbXtTZvY"
      },
      "source": [
        "### Algorithm convergence visualisation\n",
        "\n",
        "Iterations of the each **gradient descent** algorithm can be plotted as the path on 3D surface, in case model has only 2 independent parameters $\\{ \\theta_{1}, \\theta_{2} \\}$ so they can represent $X$ and $Y$ axises, and remaining $Z$ axis represents value of estimation equation to optimize $J(\\theta_{1}, \\theta_{2})$. All visualisation tools are used from [matplotlib](https://github.com/matplotlib/matplotlib) package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow88b6ykaCXq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as colormaps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1uHa2ImsASP"
      },
      "source": [
        "Useful plotting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTxudbAruJ8w"
      },
      "source": [
        "from typing import Callable\n",
        "\n",
        "\n",
        "def plot_grid(F: Callable[[np.array, np.array], np.array],\n",
        "              X: np.array, Y: np.array,\n",
        "              elev=30, azim=50, ax=None):\n",
        "  \"\"\"\n",
        "  Plots 3D surface grid for 2 independent\n",
        "  parameters and estimation equation\n",
        "  :param F: estimation equation\n",
        "  :param X: first independent parameter\n",
        "  :param Y: second independent parameter\n",
        "  :param elev: vertical rotation angle\n",
        "  :param azim: horizontal rotation angle\n",
        "  :param ax: predefined plotting axis\n",
        "  :return: generated plotting axis\n",
        "  \"\"\"\n",
        "\n",
        "  # Generating grid\n",
        "  x, y = np.meshgrid(X, Y)\n",
        "\n",
        "  # If grid plotting axis is not defined above,\n",
        "  # the new one will be created.\n",
        "  if ax is None:\n",
        "    fig = plt.figure()\n",
        "    ax = fig.gca(projection='3d')\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "\n",
        "  # Plotting grid\n",
        "  surf = ax.plot_surface(x, y, F(x, y), \n",
        "                         cmap=colormaps.coolwarm, \n",
        "                         antialiased=True)\n",
        "  fig.colorbar(surf)\n",
        "\n",
        "  # For axis reusability purposes\n",
        "  return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_bcT9ZEt8qA"
      },
      "source": [
        "### Optimization problem\n",
        "\n",
        "[Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) is chosen as an example of an optimization problem for comparing the convergence rate of the **gradient descent** algorithms. This mathematical model can be described as a binary classifier, which outputs a probability value of a certain set of features $x_{i}$ to belong to a certain class (e. g. **true** or **false**). Using the definition of optimization problem from above, the classifier can be represented in the form of two components: **an adder** that combines all the characteristics into a single one: $z = \\sum_{i=1}^{n} \\theta_{i} x_{i}$, and **a converter** that calculates the probability of the characteristics belonging to a certain class based on the output value of **an adder**: $g(z) = \\frac{1}{1 + e^{z}}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxi4Z5tF7C0c"
      },
      "source": [
        "## Gradient descent variations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5qvxjPtrKtl"
      },
      "source": [
        "## Attribution\n",
        "\n",
        "Overview is based on research paper \"An overview of gradient descent optimization algorithms\" from [arXiv.org](https://arxiv.org/pdf/1609.04747.pdf) by [Sebastian Ruder](mailto:ruder.sebastian@gmail.com) licensed under CC BY-NC-SA 4.0."
      ]
    }
  ]
}